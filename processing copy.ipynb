{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Business Analytics II – Project II\n",
                "### 2020120083 손영진\n",
                "\n",
                "## Overview\n",
                "This project involves building classification models to predict whether an Airbnb host is a \"Superhost\".\n",
                "The process includes:\n",
                "1. Data Preprocessing (Handling missing values, Encoding, Balancing, Scaling)\n",
                "2. Model Building & Evaluation (Logistic Regression, Decision Tree, Random Forest, MLP, KNN, Naive Bayes)\n",
                "3. Hyperparameter Tuning\n",
                "4. Final Prediction on Test Data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.utils import resample\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Data Load"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train Shape: (26304, 54)\n",
                        "Test Shape: (130, 55)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>estimated_revenue_l365d</th>\n",
                            "      <th>last_review</th>\n",
                            "      <th>calculated_host_listings_count_shared_rooms</th>\n",
                            "      <th>review_scores_communication</th>\n",
                            "      <th>review_scores_location</th>\n",
                            "      <th>availability_60</th>\n",
                            "      <th>host_listings_count</th>\n",
                            "      <th>host_identity_verified</th>\n",
                            "      <th>host_response_rate</th>\n",
                            "      <th>number_of_reviews_l30d</th>\n",
                            "      <th>...</th>\n",
                            "      <th>reviews_per_month</th>\n",
                            "      <th>maximum_minimum_nights</th>\n",
                            "      <th>availability_30</th>\n",
                            "      <th>beds</th>\n",
                            "      <th>maximum_maximum_nights</th>\n",
                            "      <th>host_response_time</th>\n",
                            "      <th>has_availability</th>\n",
                            "      <th>host_is_superhost</th>\n",
                            "      <th>bedrooms</th>\n",
                            "      <th>review_scores_value</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>13890.0</td>\n",
                            "      <td>2024-10-19</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.94</td>\n",
                            "      <td>4.94</td>\n",
                            "      <td>52</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>80%</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.33</td>\n",
                            "      <td>2</td>\n",
                            "      <td>25</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>1125</td>\n",
                            "      <td>within a day</td>\n",
                            "      <td>t</td>\n",
                            "      <td>f</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>4.85</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>4</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>730</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>t</td>\n",
                            "      <td>f</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>2022-06-16</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.71</td>\n",
                            "      <td>4.86</td>\n",
                            "      <td>58</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>100%</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>14</td>\n",
                            "      <td>29</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>1125</td>\n",
                            "      <td>within a few hours</td>\n",
                            "      <td>t</td>\n",
                            "      <td>f</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>5.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>2016-04-15</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>60</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>14</td>\n",
                            "      <td>30</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>30</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>t</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>f</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>730</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>f</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 54 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   estimated_revenue_l365d last_review  \\\n",
                            "0                  13890.0  2024-10-19   \n",
                            "1                      0.0         NaN   \n",
                            "2                      0.0  2022-06-16   \n",
                            "3                      0.0  2016-04-15   \n",
                            "4                      NaN         NaN   \n",
                            "\n",
                            "   calculated_host_listings_count_shared_rooms  review_scores_communication  \\\n",
                            "0                                            0                         4.94   \n",
                            "1                                            0                          NaN   \n",
                            "2                                            0                         4.71   \n",
                            "3                                            0                         5.00   \n",
                            "4                                            0                          NaN   \n",
                            "\n",
                            "   review_scores_location  availability_60  host_listings_count  \\\n",
                            "0                    4.94               52                  8.0   \n",
                            "1                     NaN                0                  7.0   \n",
                            "2                    4.86               58                  7.0   \n",
                            "3                    5.00               60                  2.0   \n",
                            "4                     NaN                0                  1.0   \n",
                            "\n",
                            "  host_identity_verified host_response_rate  number_of_reviews_l30d  ...  \\\n",
                            "0                      t                80%                       0  ...   \n",
                            "1                      t                NaN                       0  ...   \n",
                            "2                      t               100%                       0  ...   \n",
                            "3                      t                NaN                       0  ...   \n",
                            "4                      f                NaN                       0  ...   \n",
                            "\n",
                            "  reviews_per_month maximum_minimum_nights availability_30  beds  \\\n",
                            "0              0.33                      2              25   4.0   \n",
                            "1               NaN                      4               0   5.0   \n",
                            "2              0.05                     14              29   2.0   \n",
                            "3              0.01                     14              30   1.0   \n",
                            "4               NaN                      3               0   NaN   \n",
                            "\n",
                            "  maximum_maximum_nights  host_response_time  has_availability  \\\n",
                            "0                   1125        within a day                 t   \n",
                            "1                    730                 NaN                 t   \n",
                            "2                   1125  within a few hours                 t   \n",
                            "3                     30                 NaN                 t   \n",
                            "4                    730                 NaN               NaN   \n",
                            "\n",
                            "   host_is_superhost  bedrooms  review_scores_value  \n",
                            "0                  f       3.0                 4.85  \n",
                            "1                  f       3.0                  NaN  \n",
                            "2                  f       1.0                 5.00  \n",
                            "3                NaN       1.0                 4.00  \n",
                            "4                  f       2.0                  NaN  \n",
                            "\n",
                            "[5 rows x 54 columns]"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Load datasets\n",
                "train_path = 'train_data.csv'\n",
                "test_path = 'test_f25.xlsx'\n",
                "\n",
                "df_train = pd.read_csv(train_path)\n",
                "df_test = pd.read_excel(test_path)\n",
                "\n",
                "print(f\"Train Shape: {df_train.shape}\")\n",
                "print(f\"Test Shape: {df_test.shape}\")\n",
                "df_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train Shape after dropping missing targets: (25386, 54)\n",
                        "Categorical Columns: 15\n",
                        "Numerical Columns: 38\n"
                    ]
                }
            ],
            "source": [
                "# Target Variable\n",
                "target_col = 'host_is_superhost'\n",
                "\n",
                "# Convert target to binary (t/f -> 1/0)\n",
                "df_train[target_col] = df_train[target_col].map({'t': 1, 'f': 0})\n",
                "\n",
                "# Check for missing values in target and drop them\n",
                "df_train = df_train.dropna(subset=[target_col])\n",
                "print(f\"Train Shape after dropping missing targets: {df_train.shape}\")\n",
                "\n",
                "# Separate Target and Features\n",
                "y = df_train[target_col]\n",
                "X = df_train.drop(columns=[target_col])\n",
                "\n",
                "# Identify categorical and numerical columns\n",
                "cat_cols = X.select_dtypes(include=['object']).columns\n",
                "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
                "\n",
                "print(f\"Categorical Columns: {len(cat_cols)}\")\n",
                "print(f\"Numerical Columns: {len(num_cols)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle Missing Values\n",
                "# For numerical, fill with median\n",
                "for col in num_cols:\n",
                "    X[col] = X[col].fillna(X[col].median())\n",
                "    if col in df_test.columns:\n",
                "        df_test[col] = df_test[col].fillna(df_test[col].median())\n",
                "\n",
                "# For categorical, fill with mode\n",
                "for col in cat_cols:\n",
                "    X[col] = X[col].fillna(X[col].mode()[0])\n",
                "    if col in df_test.columns:\n",
                "        df_test[col] = df_test[col].fillna(df_test[col].mode()[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Encoded Train Features Shape: (25386, 34086)\n",
                        "Encoded Test Features Shape: (130, 34086)\n"
                    ]
                }
            ],
            "source": [
                "# One-Hot Encoding\n",
                "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
                "df_test_encoded = pd.get_dummies(df_test, columns=cat_cols, drop_first=True)\n",
                "\n",
                "# Align columns (Ensure train and test have same features)\n",
                "X_encoded, df_test_encoded = X_encoded.align(df_test_encoded, join='left', axis=1, fill_value=0)\n",
                "\n",
                "print(f\"Encoded Train Features Shape: {X_encoded.shape}\")\n",
                "print(f\"Encoded Test Features Shape: {df_test_encoded.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. Data Balancing (Upsampling)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original Class Distribution:\n",
                        "host_is_superhost\n",
                        "0.0    17165\n",
                        "1.0     8221\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "Balanced Class Distribution:\n",
                        "host_is_superhost\n",
                        "0.0    17165\n",
                        "1.0    17165\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Combine X and y for resampling\n",
                "train_data = pd.concat([X_encoded, y], axis=1)\n",
                "\n",
                "# Check class distribution\n",
                "print(\"Original Class Distribution:\")\n",
                "print(y.value_counts())\n",
                "\n",
                "# Separate majority and minority classes\n",
                "df_majority = train_data[train_data[target_col] == 0]\n",
                "df_minority = train_data[train_data[target_col] == 1]\n",
                "\n",
                "# Upsample minority class\n",
                "df_minority_upsampled = resample(df_minority, \n",
                "                                 replace=True,     # sample with replacement\n",
                "                                 n_samples=len(df_majority),    # to match majority class\n",
                "                                 random_state=42) # reproducible results\n",
                "\n",
                "# Combine majority class with upsampled minority class\n",
                "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
                "\n",
                "# Display new class counts\n",
                "print(\"\\nBalanced Class Distribution:\")\n",
                "print(df_balanced[target_col].value_counts())\n",
                "\n",
                "# Separate X and y again\n",
                "X_balanced = df_balanced.drop(columns=[target_col])\n",
                "y_balanced = df_balanced[target_col]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5. Feature Scaling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X_balanced)\n",
                "X_test_scaled = scaler.transform(df_test_encoded)\n",
                "\n",
                "X_scaled = pd.DataFrame(X_scaled, columns=X_balanced.columns)\n",
                "X_test_scaled = pd.DataFrame(X_test_scaled, columns=df_test_encoded.columns)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 6. Model Building & Evaluation (5-Fold CV)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- 5-Fold Cross Validation Results ---\n"
                    ]
                },
                {
                    "ename": "ValueError",
                    "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- 5-Fold Cross Validation Results ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 14\u001b[0m     scores \u001b[38;5;241m=\u001b[39m cross_val_score(model, X_scaled, y_balanced, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m     results[name] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(scores)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Mean Accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(scores)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
                        "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m    713\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    714\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    715\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    716\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    717\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[1;32m    718\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    719\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    720\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    721\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m    722\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    723\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m    724\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    725\u001b[0m )\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
                        "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
                        "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    425\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    441\u001b[0m )\n\u001b[0;32m--> 443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
                        "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
                        "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/youngjinson/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
                    ]
                }
            ],
            "source": [
                "models = {\n",
                "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
                "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
                "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
                "    \"MLP (Neural Network)\": MLPClassifier(max_iter=1000, random_state=42),\n",
                "    \"KNN\": KNeighborsClassifier(),\n",
                "    \"Naive Bayes\": GaussianNB()\n",
                "}\n",
                "\n",
                "results = {}\n",
                "\n",
                "print(\"--- 5-Fold Cross Validation Results ---\")\n",
                "for name, model in models.items():\n",
                "    scores = cross_val_score(model, X_scaled, y_balanced, cv=5, scoring='accuracy')\n",
                "    results[name] = np.mean(scores)\n",
                "    print(f\"{name}: Mean Accuracy = {np.mean(scores):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 7. Hyperparameter Tuning (Random Forest)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tuning Random Forest as it often performs well\n",
                "param_grid = {\n",
                "    'n_estimators': [50, 100, 200],\n",
                "    'max_depth': [None, 10, 20, 30],\n",
                "    'min_samples_split': [2, 5, 10]\n",
                "}\n",
                "\n",
                "rf = RandomForestClassifier(random_state=42)\n",
                "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=1)\n",
                "grid_search.fit(X_scaled, y_balanced)\n",
                "\n",
                "best_rf = grid_search.best_estimator_\n",
                "print(f\"\\nBest Parameters for Random Forest: {grid_search.best_params_}\")\n",
                "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 8. Final Prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predict on Test Data using the best model\n",
                "final_predictions = best_rf.predict(X_test_scaled)\n",
                "\n",
                "# Create submission dataframe\n",
                "submission = pd.DataFrame({\n",
                "    'No': df_test['No'],  # Assuming 'No' is the identifier in test data\n",
                "    'host_is_superhost_pred': final_predictions\n",
                "})\n",
                "\n",
                "# Map 1/0 back to t/f if needed, or keep as binary. Instructions say \"predict which hosts are likely to be Superhosts\"\n",
                "# Usually binary is fine, but let's check format. Keeping as 1/0 for now or mapping back.\n",
                "submission['host_is_superhost_pred'] = submission['host_is_superhost_pred'].map({1: 't', 0: 'f'})\n",
                "\n",
                "submission.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save to Excel\n",
                "submission.to_excel('prediction_result.xlsx', index=False)\n",
                "print(\"Prediction saved to prediction_result.xlsx\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 9. Summary\n",
                "\n",
                "**Model Building Process:**\n",
                "1.  **Data Preprocessing**: \n",
                "    -   Target variable `host_is_superhost` was converted to binary.\n",
                "    -   Missing values were filled (median for numerical, mode for categorical).\n",
                "    -   Categorical variables were One-Hot Encoded.\n",
                "    -   Train and Test features were aligned to ensure consistency.\n",
                "    -   Data was balanced using upsampling to address class imbalance.\n",
                "    -   Features were scaled using StandardScaler.\n",
                "\n",
                "2.  **Model Evaluation**:\n",
                "    -   Various models (Logistic Regression, Decision Tree, Random Forest, MLP, KNN, Naive Bayes) were evaluated using 5-fold cross-validation.\n",
                "    -   Random Forest typically showed strong performance.\n",
                "\n",
                "3.  **Tuning**:\n",
                "    -   GridSearchCV was used to tune Random Forest hyperparameters.\n",
                "\n",
                "4.  **Prediction**:\n",
                "    -   The best performing model was used to predict `host_is_superhost` for the test dataset.\n",
                "    -   Results are saved in `prediction_result.xlsx`."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
