{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Business Analytics II – Project II\n",
                "### 2020120083 손영진\n",
                "\n",
                "## Overview\n",
                "This project involves building classification models to predict whether an Airbnb host is a \"Superhost\".\n",
                "The process includes:\n",
                "1. Data Preprocessing (Handling missing values, Encoding, Balancing, Scaling)\n",
                "2. Model Building & Evaluation (Logistic Regression, Decision Tree, Random Forest, MLP, KNN, Naive Bayes)\n",
                "3. Hyperparameter Tuning\n",
                "4. Final Prediction on Test Data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.utils import resample\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Data Load"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load datasets\n",
                "train_path = 'train_data.csv'\n",
                "test_path = 'test_f25.xlsx'\n",
                "\n",
                "df_train = pd.read_csv(train_path)\n",
                "df_test = pd.read_excel(test_path)\n",
                "\n",
                "print(f\"Train Shape: {df_train.shape}\")\n",
                "print(f\"Test Shape: {df_test.shape}\")\n",
                "df_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Target Variable\n",
                "target_col = 'host_is_superhost'\n",
                "\n",
                "# Convert target to binary (t/f -> 1/0)\n",
                "df_train[target_col] = df_train[target_col].map({'t': 1, 'f': 0})\n",
                "\n",
                "# Check for missing values in target and drop them\n",
                "df_train = df_train.dropna(subset=[target_col])\n",
                "print(f\"Train Shape after dropping missing targets: {df_train.shape}\")\n",
                "\n",
                "# Separate Target and Features\n",
                "y = df_train[target_col]\n",
                "X = df_train.drop(columns=[target_col])\n",
                "\n",
                "# Identify categorical and numerical columns\n",
                "cat_cols = X.select_dtypes(include=['object']).columns\n",
                "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
                "\n",
                "print(f\"Categorical Columns: {len(cat_cols)}\")\n",
                "print(f\"Numerical Columns: {len(num_cols)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle Missing Values\n",
                "# For numerical, fill with median\n",
                "for col in num_cols:\n",
                "    X[col] = X[col].fillna(X[col].median())\n",
                "    if col in df_test.columns:\n",
                "        df_test[col] = df_test[col].fillna(df_test[col].median())\n",
                "\n",
                "# For categorical, fill with mode\n",
                "for col in cat_cols:\n",
                "    X[col] = X[col].fillna(X[col].mode()[0])\n",
                "    if col in df_test.columns:\n",
                "        df_test[col] = df_test[col].fillna(df_test[col].mode()[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# One-Hot Encoding\n",
                "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
                "df_test_encoded = pd.get_dummies(df_test, columns=cat_cols, drop_first=True)\n",
                "\n",
                "# Align columns (Ensure train and test have same features)\n",
                "X_encoded, df_test_encoded = X_encoded.align(df_test_encoded, join='left', axis=1, fill_value=0)\n",
                "\n",
                "print(f\"Encoded Train Features Shape: {X_encoded.shape}\")\n",
                "print(f\"Encoded Test Features Shape: {df_test_encoded.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. Data Balancing (Upsampling)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Combine X and y for resampling\n",
                "train_data = pd.concat([X_encoded, y], axis=1)\n",
                "\n",
                "# Check class distribution\n",
                "print(\"Original Class Distribution:\")\n",
                "print(y.value_counts())\n",
                "\n",
                "# Separate majority and minority classes\n",
                "df_majority = train_data[train_data[target_col] == 0]\n",
                "df_minority = train_data[train_data[target_col] == 1]\n",
                "\n",
                "# Upsample minority class\n",
                "df_minority_upsampled = resample(df_minority, \n",
                "                                 replace=True,     # sample with replacement\n",
                "                                 n_samples=len(df_majority),    # to match majority class\n",
                "                                 random_state=42) # reproducible results\n",
                "\n",
                "# Combine majority class with upsampled minority class\n",
                "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
                "\n",
                "# Display new class counts\n",
                "print(\"\\nBalanced Class Distribution:\")\n",
                "print(df_balanced[target_col].value_counts())\n",
                "\n",
                "# Separate X and y again\n",
                "X_balanced = df_balanced.drop(columns=[target_col])\n",
                "y_balanced = df_balanced[target_col]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5. Feature Scaling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X_balanced)\n",
                "X_test_scaled = scaler.transform(df_test_encoded)\n",
                "\n",
                "X_scaled = pd.DataFrame(X_scaled, columns=X_balanced.columns)\n",
                "X_test_scaled = pd.DataFrame(X_test_scaled, columns=df_test_encoded.columns)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 6. Model Building & Evaluation (5-Fold CV)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "models = {\n",
                "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
                "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
                "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
                "    \"MLP (Neural Network)\": MLPClassifier(max_iter=1000, random_state=42),\n",
                "    \"KNN\": KNeighborsClassifier(),\n",
                "    \"Naive Bayes\": GaussianNB()\n",
                "}\n",
                "\n",
                "results = {}\n",
                "\n",
                "print(\"--- 5-Fold Cross Validation Results ---\")\n",
                "for name, model in models.items():\n",
                "    scores = cross_val_score(model, X_scaled, y_balanced, cv=5, scoring='accuracy')\n",
                "    results[name] = np.mean(scores)\n",
                "    print(f\"{name}: Mean Accuracy = {np.mean(scores):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 7. Hyperparameter Tuning (Random Forest)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tuning Random Forest as it often performs well\n",
                "param_grid = {\n",
                "    'n_estimators': [50, 100, 200],\n",
                "    'max_depth': [None, 10, 20, 30],\n",
                "    'min_samples_split': [2, 5, 10]\n",
                "}\n",
                "\n",
                "rf = RandomForestClassifier(random_state=42)\n",
                "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=1)\n",
                "grid_search.fit(X_scaled, y_balanced)\n",
                "\n",
                "best_rf = grid_search.best_estimator_\n",
                "print(f\"\\nBest Parameters for Random Forest: {grid_search.best_params_}\")\n",
                "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 8. Final Prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predict on Test Data using the best model\n",
                "final_predictions = best_rf.predict(X_test_scaled)\n",
                "\n",
                "# Create submission dataframe\n",
                "submission = pd.DataFrame({\n",
                "    'No': df_test['No'],  # Assuming 'No' is the identifier in test data\n",
                "    'host_is_superhost_pred': final_predictions\n",
                "})\n",
                "\n",
                "# Map 1/0 back to t/f if needed, or keep as binary. Instructions say \"predict which hosts are likely to be Superhosts\"\n",
                "# Usually binary is fine, but let's check format. Keeping as 1/0 for now or mapping back.\n",
                "submission['host_is_superhost_pred'] = submission['host_is_superhost_pred'].map({1: 't', 0: 'f'})\n",
                "\n",
                "submission.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save to Excel\n",
                "submission.to_excel('prediction_result.xlsx', index=False)\n",
                "print(\"Prediction saved to prediction_result.xlsx\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 9. Summary\n",
                "\n",
                "**Model Building Process:**\n",
                "1.  **Data Preprocessing**: \n",
                "    -   Target variable `host_is_superhost` was converted to binary.\n",
                "    -   Missing values were filled (median for numerical, mode for categorical).\n",
                "    -   Categorical variables were One-Hot Encoded.\n",
                "    -   Train and Test features were aligned to ensure consistency.\n",
                "    -   Data was balanced using upsampling to address class imbalance.\n",
                "    -   Features were scaled using StandardScaler.\n",
                "\n",
                "2.  **Model Evaluation**:\n",
                "    -   Various models (Logistic Regression, Decision Tree, Random Forest, MLP, KNN, Naive Bayes) were evaluated using 5-fold cross-validation.\n",
                "    -   Random Forest typically showed strong performance.\n",
                "\n",
                "3.  **Tuning**:\n",
                "    -   GridSearchCV was used to tune Random Forest hyperparameters.\n",
                "\n",
                "4.  **Prediction**:\n",
                "    -   The best performing model was used to predict `host_is_superhost` for the test dataset.\n",
                "    -   Results are saved in `prediction_result.xlsx`."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}