{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Business Analytics II \u2013 Project II\n",
                "### 2020120083 \uc190\uc601\uc9c4\n",
                "\n",
                "## \uac1c\uc694 (Overview)\n",
                "\uc774 \ud504\ub85c\uc81d\ud2b8\ub294 \uc5d0\uc5b4\ube44\uc564\ube44 \ud638\uc2a4\ud2b8\uac00 '\uc288\ud37c\ud638\uc2a4\ud2b8'\uc778\uc9c0 \uc608\uce21\ud558\ub294 \ubd84\ub958 \ubaa8\ub378\uc744 \uad6c\ucd95\ud569\ub2c8\ub2e4. building classification models to predict whether an Airbnb host is a \"Superhost\".\n",
                "The process includes:\n",
                "1. ## 3. \ub370\uc774\ud130 \uc804\ucc98\ub9ac (Data Preprocessing) (Handling missing values, Encoding, Balancing, Scaling)\n",
                "2. ## 6. \ubaa8\ub378 \uad6c\ucd95 \ubc0f \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd (Logistic Regression, Decision Tree, Random Forest, MLP, KNN, Naive Bayes)\n",
                "3. ## 7. \ucd5c\uc885 \uc608\uce21 (Final Prediction) on Test Data using the best model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: pandas==2.2.3 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
                        "Collecting numpy==2.1.1 (from -r requirements.txt (line 2))\n",
                        "  Downloading numpy-2.1.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
                        "Collecting matplotlib==3.10.1 (from -r requirements.txt (line 3))\n",
                        "  Downloading matplotlib-3.10.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
                        "Requirement already satisfied: seaborn==0.13.2 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
                        "Collecting scikit-learn==1.6.1 (from -r requirements.txt (line 5))\n",
                        "  Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
                        "Requirement already satisfied: openpyxl==3.1.5 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.1.5)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2024.1)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2023.3)\n",
                        "Requirement already satisfied: contourpy>=1.0.1 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (1.2.0)\n",
                        "Requirement already satisfied: cycler>=0.10 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (0.11.0)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (4.51.0)\n",
                        "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (1.4.4)\n",
                        "Requirement already satisfied: packaging>=20.0 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (24.1)\n",
                        "Requirement already satisfied: pillow>=8 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (11.3.0)\n",
                        "Requirement already satisfied: pyparsing>=2.3.1 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (3.1.2)\n",
                        "Requirement already satisfied: scipy>=1.6.0 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 5)) (1.11.4)\n",
                        "Requirement already satisfied: joblib>=1.2.0 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 5)) (1.4.2)\n",
                        "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 5)) (3.5.0)\n",
                        "Requirement already satisfied: et-xmlfile in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from openpyxl==3.1.5->-r requirements.txt (line 6)) (1.1.0)\n",
                        "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
                        "Collecting contourpy>=1.0.1 (from matplotlib==3.10.1->-r requirements.txt (line 3))\n",
                        "  Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
                        "Requirement already satisfied: six>=1.5 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 1)) (1.16.0)\n",
                        "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
                        "Collecting scipy>=1.6.0 (from scikit-learn==1.6.1->-r requirements.txt (line 5))\n",
                        "  Downloading scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
                        "Downloading numpy-2.1.1-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hDownloading matplotlib-3.10.1-cp312-cp312-macosx_11_0_arm64.whl (8.0 MB)\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hDownloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (273 kB)\n",
                        "Downloading scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl (20.9 MB)\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hInstalling collected packages: numpy, scipy, contourpy, scikit-learn, matplotlib\n",
                        "  Attempting uninstall: numpy\n",
                        "    Found existing installation: numpy 1.26.4\n",
                        "    Uninstalling numpy-1.26.4:\n",
                        "      Successfully uninstalled numpy-1.26.4\n",
                        "  Attempting uninstall: scipy\n",
                        "    Found existing installation: scipy 1.11.4\n",
                        "    Uninstalling scipy-1.11.4:\n",
                        "      Successfully uninstalled scipy-1.11.4\n",
                        "  Attempting uninstall: contourpy\n",
                        "    Found existing installation: contourpy 1.2.0\n",
                        "    Uninstalling contourpy-1.2.0:\n",
                        "      Successfully uninstalled contourpy-1.2.0\n",
                        "  Attempting uninstall: scikit-learn\n",
                        "    Found existing installation: scikit-learn 1.5.1\n",
                        "    Uninstalling scikit-learn-1.5.1:\n",
                        "      Successfully uninstalled scikit-learn-1.5.1\n",
                        "  Attempting uninstall: matplotlib\n",
                        "    Found existing installation: matplotlib 3.9.2\n",
                        "    Uninstalling matplotlib-3.9.2:\n",
                        "      Successfully uninstalled matplotlib-3.9.2\n",
                        "  \u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
                        "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.1 which is incompatible.\n",
                        "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\n",
                        "crawl4ai 0.6.2 requires pillow~=10.4, but you have pillow 11.3.0 which is incompatible.\n",
                        "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.1 which is incompatible.\n",
                        "streamlit 1.51.0 requires pyarrow<22,>=7.0, but you have pyarrow 22.0.0 which is incompatible.\n",
                        "tensorflow-macos 2.16.2 requires tensorflow==2.16.2; platform_system == \"Darwin\" and platform_machine == \"arm64\", but you have tensorflow 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
                        "\u001b[0mSuccessfully installed contourpy-1.3.3 matplotlib-3.10.1 numpy-2.1.1 scikit-learn-1.6.1 scipy-1.13.1\n"
                    ]
                }
            ],
            "source": [
                "# Install requirements\n",
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import shap\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.utils import resample\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, f1_score, ConfusionMatrixDisplay\n",
                "from sentence_transformers import SentenceTransformer\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# \ud55c\uae00 \ud3f0\ud2b8 \uc124\uc815 (Mac OS \uae30\uc900)\n",
                "plt.rc('font', family='AppleGothic')\n",
                "plt.rcParams['axes.unicode_minus'] = False"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Data Load"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train Shape: (26304, 54)\n",
                        "Test Shape: (130, 55)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>estimated_revenue_l365d</th>\n",
                            "      <th>last_review</th>\n",
                            "      <th>calculated_host_listings_count_shared_rooms</th>\n",
                            "      <th>review_scores_communication</th>\n",
                            "      <th>review_scores_location</th>\n",
                            "      <th>availability_60</th>\n",
                            "      <th>host_listings_count</th>\n",
                            "      <th>host_identity_verified</th>\n",
                            "      <th>host_response_rate</th>\n",
                            "      <th>number_of_reviews_l30d</th>\n",
                            "      <th>...</th>\n",
                            "      <th>reviews_per_month</th>\n",
                            "      <th>maximum_minimum_nights</th>\n",
                            "      <th>availability_30</th>\n",
                            "      <th>beds</th>\n",
                            "      <th>maximum_maximum_nights</th>\n",
                            "      <th>host_response_time</th>\n",
                            "      <th>has_availability</th>\n",
                            "      <th>host_is_superhost</th>\n",
                            "      <th>bedrooms</th>\n",
                            "      <th>review_scores_value</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>13890.0</td>\n",
                            "      <td>2024-10-19</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.94</td>\n",
                            "      <td>4.94</td>\n",
                            "      <td>52</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>80%</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.33</td>\n",
                            "      <td>2</td>\n",
                            "      <td>25</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>1125</td>\n",
                            "      <td>within a day</td>\n",
                            "      <td>t</td>\n",
                            "      <td>f</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>4.85</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>4</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>730</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>t</td>\n",
                            "      <td>f</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>2022-06-16</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.71</td>\n",
                            "      <td>4.86</td>\n",
                            "      <td>58</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>100%</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>14</td>\n",
                            "      <td>29</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>1125</td>\n",
                            "      <td>within a few hours</td>\n",
                            "      <td>t</td>\n",
                            "      <td>f</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>5.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>2016-04-15</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>60</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>14</td>\n",
                            "      <td>30</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>30</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>t</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>f</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>730</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>f</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows \u00d7 54 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   estimated_revenue_l365d last_review  \\\n",
                            "0                  13890.0  2024-10-19   \n",
                            "1                      0.0         NaN   \n",
                            "2                      0.0  2022-06-16   \n",
                            "3                      0.0  2016-04-15   \n",
                            "4                      NaN         NaN   \n",
                            "\n",
                            "   calculated_host_listings_count_shared_rooms  review_scores_communication  \\\n",
                            "0                                            0                         4.94   \n",
                            "1                                            0                          NaN   \n",
                            "2                                            0                         4.71   \n",
                            "3                                            0                         5.00   \n",
                            "4                                            0                          NaN   \n",
                            "\n",
                            "   review_scores_location  availability_60  host_listings_count  \\\n",
                            "0                    4.94               52                  8.0   \n",
                            "1                     NaN                0                  7.0   \n",
                            "2                    4.86               58                  7.0   \n",
                            "3                    5.00               60                  2.0   \n",
                            "4                     NaN                0                  1.0   \n",
                            "\n",
                            "  host_identity_verified host_response_rate  number_of_reviews_l30d  ...  \\\n",
                            "0                      t                80%                       0  ...   \n",
                            "1                      t                NaN                       0  ...   \n",
                            "2                      t               100%                       0  ...   \n",
                            "3                      t                NaN                       0  ...   \n",
                            "4                      f                NaN                       0  ...   \n",
                            "\n",
                            "  reviews_per_month maximum_minimum_nights availability_30  beds  \\\n",
                            "0              0.33                      2              25   4.0   \n",
                            "1               NaN                      4               0   5.0   \n",
                            "2              0.05                     14              29   2.0   \n",
                            "3              0.01                     14              30   1.0   \n",
                            "4               NaN                      3               0   NaN   \n",
                            "\n",
                            "  maximum_maximum_nights  host_response_time  has_availability  \\\n",
                            "0                   1125        within a day                 t   \n",
                            "1                    730                 NaN                 t   \n",
                            "2                   1125  within a few hours                 t   \n",
                            "3                     30                 NaN                 t   \n",
                            "4                    730                 NaN               NaN   \n",
                            "\n",
                            "   host_is_superhost  bedrooms  review_scores_value  \n",
                            "0                  f       3.0                 4.85  \n",
                            "1                  f       3.0                  NaN  \n",
                            "2                  f       1.0                 5.00  \n",
                            "3                NaN       1.0                 4.00  \n",
                            "4                  f       2.0                  NaN  \n",
                            "\n",
                            "[5 rows x 54 columns]"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Load datasets\n",
                "train_path = 'train_data.csv'\n",
                "test_path = 'test_f25.xlsx'\n",
                "\n",
                "df_train = pd.read_csv(train_path)\n",
                "df_test = pd.read_excel(test_path)\n",
                "\n",
                "print(f\"Train Shape: {df_train.shape}\")\n",
                "print(f\"Test Shape: {df_test.shape}\")\n",
                "df_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. \ub370\uc774\ud130 \uc804\ucc98\ub9ac (Data Preprocessing)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train Shape after dropping missing targets: (25386, 54)\n",
                        "Categorical Columns: 15\n",
                        "Numerical Columns: 38\n"
                    ]
                }
            ],
            "source": [
                "# Target Variable\n",
                "target_col = 'host_is_superhost'\n",
                "\n",
                "# Convert target to binary (t/f -> 1/0)\n",
                "df_train[target_col] = df_train[target_col].map({'t': 1, 'f': 0})\n",
                "\n",
                "# Check for missing values in target and drop them\n",
                "df_train = df_train.dropna(subset=[target_col])\n",
                "print(f\"Train Shape after dropping missing targets: {df_train.shape}\")\n",
                "\n",
                "# Separate Target and Features\n",
                "y = df_train[target_col]\n",
                "X = df_train.drop(columns=[target_col])\n",
                "\n",
                "# Drop columns that are entirely empty (all NaNs)\n",
                "X = X.dropna(axis=1, how='all')\n",
                "\n",
                "# --- Date Processing ---\n",
                "print(\"Processing Dates...\")\n",
                "date_cols = ['last_review', 'first_review']\n",
                "for col in date_cols:\n",
                "    if col in X.columns:\n",
                "        # Convert to datetime\n",
                "        X[col] = pd.to_datetime(X[col], errors='coerce')\n",
                "        if col in df_test.columns:\n",
                "            df_test[col] = pd.to_datetime(df_test[col], errors='coerce')\n",
                "        \n",
                "        # Create 'days_since' feature (relative to a reference date, e.g., today or max date)\n",
                "        ref_date = pd.Timestamp('2024-12-01') # Use a fixed recent date\n",
                "        X[f'days_since_{col}'] = (ref_date - X[col]).dt.days\n",
                "        df_test[f'days_since_{col}'] = (ref_date - df_test[col]).dt.days\n",
                "        \n",
                "        # Drop original date columns\n",
                "        X = X.drop(columns=[col])\n",
                "        df_test = df_test.drop(columns=[col])\n",
                "\n",
                "# --- Text Embedding (Amenities) ---\n",
                "print(\"Embedding Amenities (this may take a while)...\")\n",
                "if 'amenities' in X.columns:\n",
                "    # Load pre-trained model\n",
                "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "    \n",
                "    # Fill NaNs with empty string\n",
                "    X['amenities'] = X['amenities'].fillna('')\n",
                "    df_test['amenities'] = df_test['amenities'].fillna('')\n",
                "    \n",
                "    # Encode\n",
                "    train_embeddings = model.encode(X['amenities'].tolist(), show_progress_bar=True)\n",
                "    test_embeddings = model.encode(df_test['amenities'].tolist(), show_progress_bar=True)\n",
                "    \n",
                "    # Create DataFrame from embeddings\n",
                "    embedding_cols = [f'amenity_emb_{i}' for i in range(train_embeddings.shape[1])]\n",
                "    train_emb_df = pd.DataFrame(train_embeddings, columns=embedding_cols, index=X.index)\n",
                "    test_emb_df = pd.DataFrame(test_embeddings, columns=embedding_cols, index=df_test.index)\n",
                "    \n",
                "    # Concatenate and drop original column\n",
                "    X = pd.concat([X, train_emb_df], axis=1).drop(columns=['amenities'])\n",
                "    df_test = pd.concat([df_test, test_emb_df], axis=1).drop(columns=['amenities'])\n",
                "\n",
                "# Identify categorical and numerical columns (Refresh after new features)\n",
                "cat_cols = X.select_dtypes(include=['object']).columns\n",
                "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
                "\n",
                "print(f\"Categorical Columns: {len(cat_cols)}\")\n",
                "print(f\"Numerical Columns: {len(num_cols)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle Missing Values\n",
                "# For numerical, fill with median\n",
                "for col in num_cols:\n",
                "    median_val = X[col].median()  # Calculate median on Train\n",
                "    X[col] = X[col].fillna(median_val)\n",
                "    if col in df_test.columns:\n",
                "        df_test[col] = df_test[col].fillna(median_val)  # Apply Train median to Test\n",
                "\n",
                "# For categorical, fill with mode\n",
                "for col in cat_cols:\n",
                "    mode_val = X[col].mode()[0]  # Calculate mode on Train\n",
                "    X[col] = X[col].fillna(mode_val)\n",
                "    if col in df_test.columns:\n",
                "        df_test[col] = df_test[col].fillna(mode_val)  # Apply Train mode to Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Encoded Train Features Shape: (25386, 34086)\n",
                        "Encoded Test Features Shape: (130, 34086)\n"
                    ]
                }
            ],
            "source": [
                "# One-Hot Encoding\n",
                "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
                "df_test_encoded = pd.get_dummies(df_test, columns=cat_cols, drop_first=True)\n",
                "\n",
                "# Align columns (Ensure train and test have same features)\n",
                "X_encoded, df_test_encoded = X_encoded.align(df_test_encoded, join='left', axis=1, fill_value=0)\n",
                "\n",
                "print(f\"Encoded Train Features Shape: {X_encoded.shape}\")\n",
                "print(f\"Encoded Test Features Shape: {df_test_encoded.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud074\ub798\uc2a4 \ubd88\uade0\ud615 \ucc98\ub9ac (Class Imbalance Handling)\n",
                "\ub370\uc774\ud130\uc758 \ud074\ub798\uc2a4 \ube44\uc728\uc744 \ub9de\ucd94\uae30 \uc704\ud574 \ub9ac\uc0d8\ud50c\ub9c1(Resampling)\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.\n",
                "- **\uc635\uc158**: `SAMPLING_METHOD`\ub97c `'upsample'`(\uc5c5\uc0d8\ud50c\ub9c1) \ub610\ub294 `'downsample'`(\ub2e4\uc6b4\uc0d8\ud50c\ub9c1)\ub85c \uc124\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
                "- **\uc5c5\uc0d8\ud50c\ub9c1 (Upsampling)**: \uc18c\uc218 \ud074\ub798\uc2a4 \ub370\uc774\ud130\ub97c \ubcf5\uc81c\ud558\uc5ec \ub298\ub9bd\ub2c8\ub2e4. \uc815\ubcf4 \uc190\uc2e4\uc774 \uc5c6\uc9c0\ub9cc \uacfc\uc801\ud569(Overfitting) \uc704\ud5d8\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n",
                "- **\ub2e4\uc6b4\uc0d8\ud50c\ub9c1 (Downsampling)**: \ub2e4\uc218 \ud074\ub798\uc2a4 \ub370\uc774\ud130\ub97c \uc904\uc5ec\uc11c \ub9de\ucda5\ub2c8\ub2e4. \ud559\uc2b5 \uc18d\ub3c4\ub294 \ube60\ub974\uc9c0\ub9cc \uc911\uc694\ud55c \uc815\ubcf4\uac00 \uc190\uc2e4\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original Class Distribution:\n",
                        "host_is_superhost\n",
                        "0.0    17165\n",
                        "1.0     8221\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "Performing Upsampling...\n",
                        "\n",
                        "Balanced Class Distribution:\n",
                        "host_is_superhost\n",
                        "0.0    17165\n",
                        "1.0    17165\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "SAMPLING_METHOD = 'upsample'  # Options: 'upsample', 'downsample'\n",
                "\n",
                "# Combine X and y for resampling\n",
                "train_data = pd.concat([X_encoded, y], axis=1)\n",
                "\n",
                "# Check class distribution\n",
                "print(\"Original Class Distribution:\")\n",
                "print(y.value_counts())\n",
                "\n",
                "# Separate majority and minority classes\n",
                "df_majority = train_data[train_data[target_col] == 0]\n",
                "df_minority = train_data[train_data[target_col] == 1]\n",
                "\n",
                "if SAMPLING_METHOD == 'upsample':\n",
                "    print(\"\\nPerforming Upsampling...\")\n",
                "    df_minority_upsampled = resample(df_minority, \n",
                "                                     replace=True,     # sample with replacement\n",
                "                                     n_samples=len(df_majority),    # to match majority class\n",
                "                                     random_state=42)\n",
                "    df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
                "    \n",
                "elif SAMPLING_METHOD == 'downsample':\n",
                "    print(\"\\nPerforming Downsampling...\")\n",
                "    df_majority_downsampled = resample(df_majority, \n",
                "                                       replace=False,    # sample without replacement\n",
                "                                       n_samples=len(df_minority),    # to match minority class\n",
                "                                       random_state=42)\n",
                "    df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
                "\n",
                "# Display new class counts\n",
                "print(\"\\nBalanced Class Distribution:\")\n",
                "print(df_balanced[target_col].value_counts())\n",
                "\n",
                "# Separate X and y again\n",
                "X_balanced = df_balanced.drop(columns=[target_col])\n",
                "y_balanced = df_balanced[target_col]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. \ud2b9\uc131 \uc2a4\ucf00\uc77c\ub9c1 (Feature Scaling)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X_balanced)\n",
                "X_test_scaled = scaler.transform(df_test_encoded)\n",
                "\n",
                "X_scaled = pd.DataFrame(X_scaled, columns=X_balanced.columns)\n",
                "X_test_scaled = pd.DataFrame(X_test_scaled, columns=df_test_encoded.columns)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd \uc804\ub7b5 (Hyperparameter Tuning Strategy)\n",
                "`GridSearchCV`\ub97c \uc0ac\uc6a9\ud558\uc5ec \uac01 \ubaa8\ub378\uc758 \ucd5c\uc801 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ucc3e\uc2b5\ub2c8\ub2e4. \uac01 \ub9e4\uac1c\ubcc0\uc218\uc758 \uc120\uc815 \uc774\uc720\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n",
                "\n",
                "- **MLP (\uc2e0\uacbd\ub9dd)**:\n",
                "    - `hidden_layer_sizes`: \ubaa8\ub378\uc758 \ubcf5\uc7a1\ub3c4\ub97c \uacb0\uc815\ud569\ub2c8\ub2e4. `(50,)`\uc740 \ub2e8\uc21c \ubaa8\ub378, `(50, 50)`\uc740 \ub354 \uae4a\uc740 \ud328\ud134\uc744 \ud559\uc2b5\ud569\ub2c8\ub2e4.\n",
                "    - `activation`: `relu`\ub294 \uc77c\ubc18\uc801\uc778 \ub525\ub7ec\ub2dd \ud65c\uc131\ud654 \ud568\uc218\uc774\uba70, `tanh`\ub3c4 \ud14c\uc2a4\ud2b8\ud569\ub2c8\ub2e4.\n",
                "    - `alpha`: \uacfc\uc801\ud569\uc744 \ub9c9\uae30 \uc704\ud55c \uaddc\uc81c \ud30c\ub77c\ubbf8\ud130\uc785\ub2c8\ub2e4.\n",
                "\n",
                "- **Random Forest & Decision Tree**:\n",
                "    - `max_depth`: \ud2b8\ub9ac\uc758 \uae4a\uc774\uc785\ub2c8\ub2e4. \ub108\ubb34 \uae4a\uc73c\uba74 \uacfc\uc801\ud569\ub420 \uc218 \uc788\uc5b4 \uc81c\ud55c\uc744 \ub461\ub2c8\ub2e4.\n",
                "    - `min_samples_split`: \ub178\ub4dc\ub97c \ubd84\ud560\ud558\uae30 \uc704\ud55c \ucd5c\uc18c \uc0d8\ud50c \uc218\uc785\ub2c8\ub2e4. \ud074\uc218\ub85d \uc77c\ubc18\ud654\uc5d0 \uc720\ub9ac\ud569\ub2c8\ub2e4.\n",
                "\n",
                "- **KNN**:\n",
                "    - `n_neighbors`: \uc774\uc6c3\uc758 \uc218\uc785\ub2c8\ub2e4. \uc791\uc73c\uba74 \ub178\uc774\uc988\uc5d0 \ubbfc\uac10\ud558\uace0, \ud06c\uba74 \ub108\ubb34 \ub2e8\uc21c\ud574\uc9c8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
                "    - `weights`: `distance`\ub294 \uac00\uae4c\uc6b4 \uc774\uc6c3\uc5d0\uac8c \ub354 \ud070 \uac00\uc911\uce58\ub97c \uc90d\ub2c8\ub2e4.\n",
                "\n",
                "- **Logistic Regression**:\n",
                "    - `C`: \uaddc\uc81c \uac15\ub3c4\uc758 \uc5ed\uc218\uc785\ub2c8\ub2e4. \uc791\uc744\uc218\ub85d \uaddc\uc81c\uac00 \uac15\ud574\uc838 \uacfc\uc801\ud569\uc744 \ub9c9\uc2b5\ub2c8\ub2e4."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize results list and best_models dictionary\n",
                "# Run this cell once before running individual model cells\n",
                "results = []\n",
                "best_models = {}\n",
                "\n",
                "def visualize_model_result(name, model, X, y):\n",
                "    # \ud63c\ub3d9 \ud589\ub82c \uc2dc\uac01\ud654\n",
                "    y_pred = model.predict(X)\n",
                "    cm = confusion_matrix(y, y_pred)\n",
                "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Superhost', 'Superhost'])\n",
                "    disp.plot(cmap=plt.cm.Blues)\n",
                "    plt.title(f'{name} - \ud63c\ub3d9 \ud589\ub82c (Confusion Matrix)')\n",
                "    plt.show()\n",
                "    \n",
                "    # \ud2b9\uc131 \uc911\uc694\ub3c4 \uc2dc\uac01\ud654 (\ud2b8\ub9ac \uae30\ubc18 \ubaa8\ub378)\n",
                "    if hasattr(model, 'feature_importances_'):\n",
                "        importances = model.feature_importances_\n",
                "        indices = np.argsort(importances)[::-1][:20] # \uc0c1\uc704 20\uac1c\n",
                "        \n",
                "        plt.figure(figsize=(10, 6))\n",
                "        plt.title(f'{name} - \uc0c1\uc704 20\uac1c \ud2b9\uc131 \uc911\uc694\ub3c4 (Feature Importance)')\n",
                "        plt.bar(range(len(indices)), importances[indices], align='center')\n",
                "        plt.xticks(range(len(indices)), [X.columns[i] for i in indices], rotation=90)\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "        \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing Logistic Regression ---\")\n",
                "lr_params = {\n",
                "    'C': [1]\n",
                "}\n",
                "clf = GridSearchCV(LogisticRegression(max_iter=100, random_state=42), lr_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['Logistic Regression'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'Logistic Regression',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")\n",
                "    # \uacb0\uacfc \uc2dc\uac01\ud654\n",
                "    visualize_model_result(name, clf.best_estimator_, X_scaled, y_balanced)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing Decision Tree ---\")\n",
                "dt_params = {\n",
                "    'max_depth': [None],\n",
                "    'min_samples_split': [2]\n",
                "}\n",
                "clf = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['Decision Tree'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'Decision Tree',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")\n",
                "    # \uacb0\uacfc \uc2dc\uac01\ud654\n",
                "    visualize_model_result(name, clf.best_estimator_, X_scaled, y_balanced)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing Random Forest ---\")\n",
                "rf_params = {\n",
                "    'n_estimators': [100],\n",
                "    'max_depth': [None],\n",
                "    'min_samples_split': [2]\n",
                "}\n",
                "clf = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['Random Forest'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'Random Forest',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")\n",
                "    # \uacb0\uacfc \uc2dc\uac01\ud654\n",
                "    visualize_model_result(name, clf.best_estimator_, X_scaled, y_balanced)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing MLP (Neural Network) ---\")\n",
                "mlp_params = {\n",
                "    'hidden_layer_sizes': [(50, 50)],\n",
                "    'activation': ['relu'],\n",
                "    'alpha': [0.001]\n",
                "}\n",
                "clf = GridSearchCV(MLPClassifier(max_iter=100, random_state=42), mlp_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['MLP (Neural Network)'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'MLP (Neural Network)',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")\n",
                "    # \uacb0\uacfc \uc2dc\uac01\ud654\n",
                "    visualize_model_result(name, clf.best_estimator_, X_scaled, y_balanced)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing KNN ---\")\n",
                "knn_params = {\n",
                "    'n_neighbors': [7],\n",
                "    'weights': ['distance']\n",
                "}\n",
                "clf = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['KNN'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'KNN',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")\n",
                "    # \uacb0\uacfc \uc2dc\uac01\ud654\n",
                "    visualize_model_result(name, clf.best_estimator_, X_scaled, y_balanced)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing Naive Bayes ---\")\n",
                "nb_params = {}\n",
                "clf = GridSearchCV(GaussianNB(), nb_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['Naive Bayes'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'Naive Bayes',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")\n",
                "    # \uacb0\uacfc \uc2dc\uac01\ud654\n",
                "    visualize_model_result(name, clf.best_estimator_, X_scaled, y_balanced)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display results dataframe\n",
                "results_df = pd.DataFrame(results).sort_values(by='Best Score', ascending=False)\n",
                "print(\"\\n--- Model Selection Report ---\")\n",
                "print(results_df)\n",
                "\n",
                "# Select the best performing model overall\n",
                "if not results_df.empty:\n",
                "    best_model_name = results_df.iloc[0]['Model']\n",
                "    best_model_score = results_df.iloc[0]['Best Score']\n",
                "    final_model = best_models[best_model_name]\n",
                "\n",
                "    print(f\"\\nSelected Best Model: {best_model_name}\")\n",
                "    print(f\"Reason: It achieved the highest cross-validation accuracy of {best_model_score:.4f} among all tested models.\")\n",
                "    \n",
                "    # Compare with Rule-Based\n",
                "else:\n",
                "    print(\"No results found. Please run the model cells above.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Rule-Based Validation ---\n",
                "print(\"\\n--- Rule-Based Validation ---\")\n",
                "\n",
                "def check_superhost_criteria(row):\n",
                "    # Criteria based on Airbnb Superhost requirements\n",
                "    # 1. 10+ stays (or 3 stays + 100 nights) -> approximated by number_of_reviews_ltm >= 10\n",
                "    # 2. Response rate >= 90%\n",
                "    # 3. Rating >= 4.8\n",
                "    # 4. Cancellation rate < 1% (Not available in dataset, assumed met)\n",
                "    \n",
                "    # Rating Check\n",
                "    rating_ok = False\n",
                "    if pd.notna(row.get('review_scores_rating')):\n",
                "        rating_ok = row['review_scores_rating'] >= 4.8\n",
                "    elif pd.notna(row.get('review_scores_value')):\n",
                "        rating_ok = row['review_scores_value'] >= 4.8\n",
                "        \n",
                "    # Response Rate Check\n",
                "    response_ok = False\n",
                "    if pd.notna(row.get('host_response_rate')):\n",
                "        # Convert '100%' string to 100 number\n",
                "        try:\n",
                "            rate = float(str(row['host_response_rate']).replace('%', ''))\n",
                "            response_ok = rate >= 90\n",
                "        except:\n",
                "            pass\n",
                "    else:\n",
                "        # If missing, assume ok if other criteria met (lenient)\n",
                "        response_ok = True\n",
                "            \n",
                "    # Stays Check\n",
                "    stays_ok = False\n",
                "    if pd.notna(row.get('number_of_reviews_ltm')):\n",
                "        stays_ok = row['number_of_reviews_ltm'] >= 10\n",
                "    elif pd.notna(row.get('number_of_reviews')):\n",
                "        stays_ok = row['number_of_reviews'] >= 10\n",
                "        \n",
                "    return 1 if (rating_ok and response_ok and stays_ok) else 0\n",
                "\n",
                "# Apply to Test Data (Need original columns, so we reload or use df_test before dropping)\n",
                "# Since we dropped columns in preprocessing, we'll reload a fresh copy for this validation\n",
                "df_test_raw = pd.read_excel('test_f25.xlsx')\n",
                "rule_based_preds = df_test_raw.apply(check_superhost_criteria, axis=1)\n",
                "\n",
                "print(f\"Rule-Based Predictions (First 10): {rule_based_preds.head(10).tolist()}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 7. \ucd5c\uc885 \uc608\uce21 (Final Prediction)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predict on Test Data\n",
                "final_predictions = final_model.predict(X_test_scaled)\n",
                "\n",
                "# Create submission dataframe\n",
                "submission = pd.DataFrame({\n",
                "    'No': df_test['No'],\n",
                "    'host_is_superhost_pred': final_predictions\n",
                "})\n",
                "\n",
                "# Map 1/0 back to t/f\n",
                "submission['host_is_superhost_pred'] = submission['host_is_superhost_pred'].map({1: 't', 0: 'f'})\n",
                "\n",
                "submission.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# \uacb0\uacfc \uc800\uc7a5 (test_f25.xlsx \ud30c\uc77c\uc758 \ube48 \uc5f4 \ucc44\uc6b0\uae30)\n",
                "try:\n",
                "    # \uc6d0\ubcf8 \ud30c\uc77c \ub2e4\uc2dc \ub85c\ub4dc (\ud3ec\ub9f7 \uc720\uc9c0)\n",
                "    submission_df = pd.read_excel('test_f25.xlsx')\n",
                "    \n",
                "    # \uc608\uce21\uac12 \ub9e4\ud551 (1 -> t, 0 -> f)\n",
                "    pred_labels = ['t' if p == 1 else 'f' for p in final_predictions]\n",
                "    \n",
                "    # \ud0c0\uac9f \uceec\ub7fc \uc774\ub984 \ud655\uc778 (\ubcf4\ud1b5 \ube44\uc5b4\uc788\uac70\ub098 'host_is_superhost'\uc77c \uac83)\n",
                "    target_col_name = 'host_is_superhost'\n",
                "    if target_col_name not in submission_df.columns:\n",
                "        # \ub9cc\uc57d \uceec\ub7fc\uc774 \uc5c6\ub2e4\uba74 \uc0c8\ub85c \uc0dd\uc131, \uc788\ub2e4\uba74 \ub36e\uc5b4\uc4f0\uae30\n",
                "        submission_df[target_col_name] = pred_labels\n",
                "    else:\n",
                "        submission_df[target_col_name] = pred_labels\n",
                "        \n",
                "    # \uc800\uc7a5\n",
                "    submission_df.to_excel('prediction_result.xlsx', index=False)\n",
                "    print(\"\uc608\uce21 \uacb0\uacfc\uac00 'prediction_result.xlsx'\uc5d0 \uc800\uc7a5\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\")\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"\uacb0\uacfc \uc800\uc7a5 \uc911 \uc624\ub958 \ubc1c\uc0dd: {e}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 8. \uc694\uc57d (Summary)\n",
                "\n",
                "**\ubaa8\ub378 \uad6c\ucd95 \uacfc\uc815 (Model Building Process):**\n",
                "1.  **\ub370\uc774\ud130 \uc804\ucc98\ub9ac (Data Preprocessing)**: \n",
                "    -   \ud0c0\uac9f \ubcc0\uc218 `host_is_superhost`\ub97c \uc774\uc9c4\uac12(binary)\uc73c\ub85c \ubcc0\ud658\ud588\uc2b5\ub2c8\ub2e4.\n",
                "    -   \uacb0\uce21\uce58\ub97c \ub300\uccb4\ud588\uc2b5\ub2c8\ub2e4 (\uc218\uce58\ud615 \ubcc0\uc218\ub294 \uc911\uc559\uac12, \ubc94\uc8fc\ud615 \ubcc0\uc218\ub294 \ucd5c\ube48\uac12).\n",
                "    -   \ubc94\uc8fc\ud615 \ubcc0\uc218\uc5d0 \ub300\ud574 \uc6d0-\ud56b \uc778\ucf54\ub529(One-Hot Encoding)\uc744 \uc218\ud589\ud588\uc2b5\ub2c8\ub2e4.\n",
                "    -   \ub370\uc774\ud130 \uc77c\uad00\uc131\uc744 \ubcf4\uc7a5\ud558\uae30 \uc704\ud574 \ud559\uc2b5(Train) \ubc0f \ud14c\uc2a4\ud2b8(Test)\uc758 \ud2b9\uc131(Feature)\ub4e4\uc744 \ub3d9\uc77c\ud558\uac8c \ub9de\ucdc4\uc2b5\ub2c8\ub2e4.\n",
                "    -   \ud074\ub798\uc2a4 \ubd88\uade0\ud615 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574 \uc5c5\uc0d8\ud50c\ub9c1(upsampling)\uc744 \uc0ac\uc6a9\ud558\uc5ec \ub370\uc774\ud130 \uade0\ud615\uc744 \ub9de\ucdc4\uc2b5\ub2c8\ub2e4.\n",
                "    -   StandardScaler\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubcc0\uc218 \uc2a4\ucf00\uc77c\ub9c1\uc744 \uc218\ud589\ud588\uc2b5\ub2c8\ub2e4.\n",
                "\n",
                "2.  **\ubaa8\ub378 \ud3c9\uac00 \ubc0f \ud29c\ub2dd (Model Evaluation & Tuning)**:\n",
                "    -   \ub2e4\uc591\ud55c \ubaa8\ub378(\ub85c\uc9c0\uc2a4\ud2f1 \ud68c\uadc0, \uc758\uc0ac\uacb0\uc815\ub098\ubb34, \ub79c\ub364 \ud3ec\ub808\uc2a4\ud2b8, MLP, KNN, \ub098\uc774\ube0c \ubca0\uc774\uc988)\uc5d0 \ub300\ud574 GridSearchCV\ub97c \uc218\ud589\ud588\uc2b5\ub2c8\ub2e4.\n",
                "    -   MLP\uc758 \uc740\ub2c9\uce35, \uc758\uc0ac\uacb0\uc815\ub098\ubb34/\ub79c\ub364 \ud3ec\ub808\uc2a4\ud2b8\uc758 \ud2b8\ub9ac \uae4a\uc774, KNN\uc758 \uc774\uc6c3 \uc218\uc640 \uac19\uc740 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ud29c\ub2dd\ud588\uc2b5\ub2c8\ub2e4.\n",
                "    -   \uc548\uc815\uc801\uc778 \ud3c9\uac00\ub97c \uc704\ud574 5-fold \uad50\ucc28 \uac80\uc99d(cross-validation)\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.\n",
                "\n",
                "3.  **\uc608\uce21 (Prediction)**:\n",
                "    -   \uad50\ucc28 \uac80\uc99d \uc815\ud655\ub3c4\uac00 \uac00\uc7a5 \ub192\uc740 \ubaa8\ub378\uc744 \uc120\ud0dd\ud588\uc2b5\ub2c8\ub2e4.\n",
                "    -   \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c \uc608\uce21\uc744 \uc0dd\uc131\ud558\uc5ec `prediction_result.xlsx` \ud30c\uc77c\ub85c \uc800\uc7a5\ud588\uc2b5\ub2c8\ub2e4."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 8. \uc124\uba85 \uac00\ub2a5\ud55c AI \ubc0f \ubd84\uc11d (Analysis & Explainable AI)\n",
                "\n",
                "\uc5ec\uae30\uc11c\ub294 \ucd5c\uc885 \uc120\ud0dd\ub41c \ubaa8\ub378\uc774 **\uc65c** \uadf8\ub7f0 \uc608\uce21\uc744 \ud588\ub294\uc9c0(SHAP), \uadf8\ub9ac\uace0 \uc6b0\ub9ac\uac00 \uc54c\uace0 \uc788\ub294 **\ub8f0\ubca0\uc774\uc2a4(Airbnb \uacf5\uc2dd \uae30\uc900)**\uc640 \uc5bc\ub9c8\ub098 \uc77c\uce58\ud558\ub294\uc9c0 \uc0ac\ud6c4 \ubd84\uc11d\ud569\ub2c8\ub2e4."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Airbnb \uae30\uc900**\n",
                "\n",
                "### \u2705 \uc288\ud37c\ud638\uc2a4\ud2b8\uac00 \ub418\uae30 \uc704\ud55c \uc8fc\uc694 \uc870\uac74\n",
                "\n",
                "(\ucd5c\uadfc 12\uac1c\uc6d4 \ud65c\ub3d9\uc744 \uae30\uc900\uc73c\ub85c, \ud3c9\uac00 \ub0a0\uc9dc\ub9c8\ub2e4 \uc790\ub3d9 \ud3c9\uac00\ub428) [Airbnb**+2**Airbnb**+2**](https://www.airbnb.com/help/article/829?utm_source=chatgpt.com)\n",
                "\n",
                "1. \uc219\uc18c \uc18c\uc720\uc790 \uacc4\uc815\uc774\uc5b4\uc57c \ud568 (\uacf5\ub3d9\ud638\uc2a4\ud2b8  \ub610\ub294 \uccb4\ud5d8/\uc11c\ube44\uc2a4 \ud638\uc2a4\ud2b8\ub294 \uae30\uc900 \ub300\uc0c1\uc774 \uc544\ub2d8) [Airbnb**+1**](https://www.airbnb.co.in/resources/hosting-homes/a/get-fast-expert-help-with-dedicated-superhost-support-445?utm_source=chatgpt.com)\n",
                "2. \ucd5c\uc18c \u201c10\uac74 \uc774\uc0c1\uc758 \uc608\uc57d \uc644\ub8cc\u201d \ub610\ub294 \u201c3\uac74 \uc774\uc0c1\uc758 \uc608\uc57d\uc774\uba74\uc11c \ucd1d 100\ubc15 \uc774\uc0c1\u201d \uc219\ubc15 \uc644\ub8cc\uc5ec\uc57c \ud568. [Airbnb**+1**](https://www.airbnb.com/help/article/829?utm_source=chatgpt.com)\n",
                "3. \uc751\ub2f5\ub960(response rate)\uc774 90% \uc774\uc0c1\uc774\uc5b4\uc57c \ud568. [Airbnb**+1**](https://www.airbnb.com/help/article/829?utm_source=chatgpt.com)\n",
                "4. \uc608\uc57d \ucde8\uc18c\uc728(cancellation rate)\uc774 1% \ubbf8\ub9cc\uc774\uc5b4\uc57c \ud568 (\ub2e8, \uc790\uc5f0\uc7ac\ud574 \ub4f1\uc758 \ubd88\uac00\ud53c\ud55c \uc0ac\uc720\ub294 \uc608\uc678) [Airbnb**+1**](https://www.airbnb.com/help/article/829?utm_source=chatgpt.com)\n",
                "5. \uc804\uccb4 \uc219\ubc15\ud3c9\uc810(overall rating)\uc774 4.8 \uc774\uc0c1\uc774\uc5b4\uc57c \ud568. [Airbnb**+1**](https://www.airbnb.com/help/article/829?utm_source=chatgpt.com)\n",
                "\n",
                "---\n",
                "\n",
                "### \ud83d\udd52 \ud3c9\uac00 \uc2dc\uc810\n",
                "\n",
                "* \ud3c9\uac00\uc8fc\uae30\ub294 **\ub9e4 3\uac1c\uc6d4\ub9c8\ub2e4(\ubd84\uae30\ub9c8\ub2e4)** \uc9c4\ud589\ub428. [Airbnb**+1**](https://www.airbnb.com.mt/help/article/3526?utm_source=chatgpt.com)\n",
                "* \ud3c9\uac00 \ub0a0\uc9dc\ub294 \ub300\ub7b5 **1 \uc6d4 1\uc77c, 4 \uc6d4 1\uc77c, 7 \uc6d4 1\uc77c, 10 \uc6d4 1\uc77c** \ub4f1\uc784. [Airbnb](https://www.airbnb.co.in/resources/hosting-homes/a/get-fast-expert-help-with-dedicated-superhost-support-445?utm_source=chatgpt.com)\n",
                "* \uc989, \ucd5c\uadfc 12\uac1c\uc6d4 \ub3d9\uc548\uc758 \uc9c0\ud45c\ub97c \uc774 \ud3c9\uac00\uc77c \uae30\uc900\uc73c\ub85c \uacc4\uc0b0\ud574\uc11c \uc790\uaca9 \ucda9\uc871 \uc5ec\ubd80\ub97c \ud310\ub2e8\ud568. [Airbnb](https://www.airbnb.com/help/article/829?utm_source=chatgpt.com)\n",
                "\n",
                "---\n",
                "\n",
                "### \ud83d\udd0d \ucc38\uace0\ud560 \ub9cc\ud55c \uc810\n",
                "\n",
                "* \u201c\uc608\uc57d \uc644\ub8cc \uac74\uc218\u201d\ub294 \ub2e8\uc21c\ud788 \uc608\uc57d\ub9cc\uc774 \uc544\ub2c8\ub77c \uc2e4\uc81c \uc219\ubc15\uc774 \uc644\ub8cc\ub41c \uac74\uc218\ub97c \uc758\ubbf8\ud568. [Airbnb](https://www.airbnb.com/help/article/829?utm_source=chatgpt.com)\n",
                "* \u201c\uc751\ub2f5\ub960\u201d\uc740 \uac8c\uc2a4\ud2b8 \ubb38\uc758\ub098 \uc608\uc57d \uc694\uccad\uc5d0 \ub300\ud574 \uc77c\uc815 \uc2dc\uac04 \uc548\uc5d0 \uc751\ub2f5\ud55c \ube44\uc728\uc784. [Hostex](https://hostex.io/blog/airbnb-superhost/?utm_source=chatgpt.com)\n",
                "* \u201c\ucde8\uc18c\uc728\u201d\uc740 \ud638\uc2a4\ud2b8\uac00 \uc790\uc758\uc801\uc73c\ub85c \uc608\uc57d\uc744 \ucde8\uc18c\ud55c \ube44\uc728\uc744 \uc758\ubbf8\ud558\uba70, \ubd88\uac00\ud53c\ud55c \uc0ac\uc720\ub294 \uce74\uc6b4\ud2b8\uc5d0\uc11c \uc81c\uc678\ub420 \uc218 \uc788\uc74c."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 8. \uc124\uba85 \uac00\ub2a5\ud55c AI \ubc0f \ubd84\uc11d (Explainable AI & Analysis) ---\n",
                "print(\"\\n--- \uc124\uba85 \uac00\ub2a5\ud55c AI \ubc0f \ubd84\uc11d (Explainable AI & Analysis) ---\")\n",
                "\n",
                "# 1. \ub8f0\ubca0\uc774\uc2a4 \ubaa8\ub378\uacfc \ube44\uad50 \ubd84\uc11d (Comparison with Rule-Based Logic)\n",
                "print(\"\\n--- \ub8f0\ubca0\uc774\uc2a4 \ubaa8\ub378\uacfc \ube44\uad50 \ubd84\uc11d (Comparison with Rule-Based Logic) ---\")\n",
                "print(\"\ub8f0\ubca0\uc774\uc2a4 \ub85c\uc9c1: Airbnb \uacf5\uc2dd \uc288\ud37c\ud638\uc2a4\ud2b8 \uae30\uc900 (\ud3c9\uc810 4.8+, \uc751\ub2f5\ub960 90%+, 10+ \uc219\ubc15 \ub4f1) \uc801\uc6a9\")\n",
                "\n",
                "final_preds = final_model.predict(X_test_scaled)\n",
                "agreement = (final_preds == rule_based_preds).mean()\n",
                "print(f\"\ucd5c\uc801 \ubaa8\ub378\uacfc \ub8f0\ubca0\uc774\uc2a4 \ub85c\uc9c1 \uac04\uc758 \uc77c\uce58\uc728: {agreement:.2%}\")\n",
                "\n",
                "# \ubd88\uc77c\uce58 \uc0ac\ub840 \ubd84\uc11d (\uc635\uc158)\n",
                "disagreements = df_test_raw[final_preds != rule_based_preds]\n",
                "if not disagreements.empty:\n",
                "    print(f\"\\n\ubd88\uc77c\uce58 \uc0ac\ub840 \uc218: {len(disagreements)}\")\n",
                "    print(\"\ubd88\uc77c\uce58 \uc0ac\ub840 \uc77c\ubd80:\")\n",
                "    print(disagreements[['host_response_rate', 'review_scores_rating', 'number_of_reviews_ltm']].head())\n",
                "\n",
                "# 2. SHAP\uc744 \uc774\uc6a9\ud55c \ubaa8\ub378 \uc124\uba85 (Explainable AI with SHAP)\n",
                "print(\"\\n--- SHAP\uc744 \uc774\uc6a9\ud55c \ubaa8\ub378 \uc124\uba85 (Explainable AI with SHAP) ---\")\n",
                "\n",
                "# \ucd5c\uc801 \ubaa8\ub378\uc774 \ud2b8\ub9ac \uae30\ubc18\uc778\uc9c0 \ud655\uc778 (Random Forest \ub4f1)\n",
                "if hasattr(final_model, 'feature_importances_'):\n",
                "    # \uc694\uc57d \ud50c\ub86f (Summary Plot)\n",
                "    explainer = shap.TreeExplainer(final_model)\n",
                "    # \ub370\uc774\ud130\uac00 \ub108\ubb34 \ud06c\uba74 \uc77c\ubd80\ub9cc \uc0d8\ud50c\ub9c1\ud558\uc5ec \uc124\uba85\n",
                "    X_sample = X_scaled.sample(n=min(100, len(X_scaled)), random_state=42)\n",
                "    shap_values = explainer.shap_values(X_sample)\n",
                "    \n",
                "    print(\"SHAP Summary Plot (\uc804\uccb4\uc801\uc778 \ud2b9\uc131 \uc601\ud5a5\ub825):\")\n",
                "    shap.summary_plot(shap_values, X_sample, plot_type=\"bar\")\n",
                "    print(\"SHAP Summary Plot (\ud074\ub798\uc2a4\ubcc4 \uc0c1\uc138 \uc601\ud5a5\ub825):\")\n",
                "    # \ub2e4\uc911 \ud074\ub798\uc2a4\uc77c \uacbd\uc6b0, 1\ubc88 \ud074\ub798\uc2a4(\uc288\ud37c\ud638\uc2a4\ud2b8)\uc5d0 \ub300\ud55c \uc124\uba85\ub9cc \ucd9c\ub825\n",
                "    if isinstance(shap_values, list):\n",
                "        shap.summary_plot(shap_values[1], X_sample)\n",
                "    else:\n",
                "        shap.summary_plot(shap_values, X_sample)\n",
                "else:\n",
                "    print(\"\uc120\ud0dd\ub41c \ubaa8\ub378\uc740 SHAP TreeExplainer\ub97c \uc9c0\uc6d0\ud558\uc9c0 \uc54a\uac70\ub098 \ud2b9\uc131 \uc911\uc694\ub3c4\ub97c \uc81c\uacf5\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}