{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Business Analytics II \u2013 Project II\n",
                "### 2020120083 \uc190\uc601\uc9c4\n",
                "\n",
                "## Overview\n",
                "This project involves building classification models to predict whether an Airbnb host is a \"Superhost\".\n",
                "The process includes:\n",
                "1. Data Preprocessing (Handling missing values, Encoding, Balancing, Scaling)\n",
                "2. Model Building & Hyperparameter Tuning (Logistic Regression, Decision Tree, Random Forest, MLP, KNN, Naive Bayes)\n",
                "3. Final Prediction on Test Data using the best model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: pandas==2.2.3 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
                        "Collecting numpy==2.1.1 (from -r requirements.txt (line 2))\n",
                        "  Downloading numpy-2.1.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
                        "Collecting matplotlib==3.10.1 (from -r requirements.txt (line 3))\n",
                        "  Downloading matplotlib-3.10.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
                        "Requirement already satisfied: seaborn==0.13.2 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
                        "Collecting scikit-learn==1.6.1 (from -r requirements.txt (line 5))\n",
                        "  Downloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
                        "Requirement already satisfied: openpyxl==3.1.5 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.1.5)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2024.1)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from pandas==2.2.3->-r requirements.txt (line 1)) (2023.3)\n",
                        "Requirement already satisfied: contourpy>=1.0.1 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (1.2.0)\n",
                        "Requirement already satisfied: cycler>=0.10 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (0.11.0)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (4.51.0)\n",
                        "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (1.4.4)\n",
                        "Requirement already satisfied: packaging>=20.0 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (24.1)\n",
                        "Requirement already satisfied: pillow>=8 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (11.3.0)\n",
                        "Requirement already satisfied: pyparsing>=2.3.1 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from matplotlib==3.10.1->-r requirements.txt (line 3)) (3.1.2)\n",
                        "Requirement already satisfied: scipy>=1.6.0 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 5)) (1.11.4)\n",
                        "Requirement already satisfied: joblib>=1.2.0 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 5)) (1.4.2)\n",
                        "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 5)) (3.5.0)\n",
                        "Requirement already satisfied: et-xmlfile in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from openpyxl==3.1.5->-r requirements.txt (line 6)) (1.1.0)\n",
                        "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
                        "Collecting contourpy>=1.0.1 (from matplotlib==3.10.1->-r requirements.txt (line 3))\n",
                        "  Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
                        "Requirement already satisfied: six>=1.5 in /Users/youngjinson/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r requirements.txt (line 1)) (1.16.0)\n",
                        "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
                        "Collecting scipy>=1.6.0 (from scikit-learn==1.6.1->-r requirements.txt (line 5))\n",
                        "  Downloading scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
                        "Downloading numpy-2.1.1-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hDownloading matplotlib-3.10.1-cp312-cp312-macosx_11_0_arm64.whl (8.0 MB)\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hDownloading scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (273 kB)\n",
                        "Downloading scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl (20.9 MB)\n",
                        "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hInstalling collected packages: numpy, scipy, contourpy, scikit-learn, matplotlib\n",
                        "  Attempting uninstall: numpy\n",
                        "    Found existing installation: numpy 1.26.4\n",
                        "    Uninstalling numpy-1.26.4:\n",
                        "      Successfully uninstalled numpy-1.26.4\n",
                        "  Attempting uninstall: scipy\n",
                        "    Found existing installation: scipy 1.11.4\n",
                        "    Uninstalling scipy-1.11.4:\n",
                        "      Successfully uninstalled scipy-1.11.4\n",
                        "  Attempting uninstall: contourpy\n",
                        "    Found existing installation: contourpy 1.2.0\n",
                        "    Uninstalling contourpy-1.2.0:\n",
                        "      Successfully uninstalled contourpy-1.2.0\n",
                        "  Attempting uninstall: scikit-learn\n",
                        "    Found existing installation: scikit-learn 1.5.1\n",
                        "    Uninstalling scikit-learn-1.5.1:\n",
                        "      Successfully uninstalled scikit-learn-1.5.1\n",
                        "  Attempting uninstall: matplotlib\n",
                        "    Found existing installation: matplotlib 3.9.2\n",
                        "    Uninstalling matplotlib-3.9.2:\n",
                        "      Successfully uninstalled matplotlib-3.9.2\n",
                        "  \u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
                        "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.1 which is incompatible.\n",
                        "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.3 which is incompatible.\n",
                        "crawl4ai 0.6.2 requires pillow~=10.4, but you have pillow 11.3.0 which is incompatible.\n",
                        "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.1 which is incompatible.\n",
                        "streamlit 1.51.0 requires pyarrow<22,>=7.0, but you have pyarrow 22.0.0 which is incompatible.\n",
                        "tensorflow-macos 2.16.2 requires tensorflow==2.16.2; platform_system == \"Darwin\" and platform_machine == \"arm64\", but you have tensorflow 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
                        "\u001b[0mSuccessfully installed contourpy-1.3.3 matplotlib-3.10.1 numpy-2.1.1 scikit-learn-1.6.1 scipy-1.13.1\n"
                    ]
                }
            ],
            "source": [
                "# Install requirements\n",
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.utils import resample\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, f1_score\n",
                "from sentence_transformers import SentenceTransformer\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Data Load"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train Shape: (26304, 54)\n",
                        "Test Shape: (130, 55)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>estimated_revenue_l365d</th>\n",
                            "      <th>last_review</th>\n",
                            "      <th>calculated_host_listings_count_shared_rooms</th>\n",
                            "      <th>review_scores_communication</th>\n",
                            "      <th>review_scores_location</th>\n",
                            "      <th>availability_60</th>\n",
                            "      <th>host_listings_count</th>\n",
                            "      <th>host_identity_verified</th>\n",
                            "      <th>host_response_rate</th>\n",
                            "      <th>number_of_reviews_l30d</th>\n",
                            "      <th>...</th>\n",
                            "      <th>reviews_per_month</th>\n",
                            "      <th>maximum_minimum_nights</th>\n",
                            "      <th>availability_30</th>\n",
                            "      <th>beds</th>\n",
                            "      <th>maximum_maximum_nights</th>\n",
                            "      <th>host_response_time</th>\n",
                            "      <th>has_availability</th>\n",
                            "      <th>host_is_superhost</th>\n",
                            "      <th>bedrooms</th>\n",
                            "      <th>review_scores_value</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>13890.0</td>\n",
                            "      <td>2024-10-19</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.94</td>\n",
                            "      <td>4.94</td>\n",
                            "      <td>52</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>80%</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.33</td>\n",
                            "      <td>2</td>\n",
                            "      <td>25</td>\n",
                            "      <td>4.0</td>\n",
                            "      <td>1125</td>\n",
                            "      <td>within a day</td>\n",
                            "      <td>t</td>\n",
                            "      <td>f</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>4.85</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>4</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5.0</td>\n",
                            "      <td>730</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>t</td>\n",
                            "      <td>f</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>2022-06-16</td>\n",
                            "      <td>0</td>\n",
                            "      <td>4.71</td>\n",
                            "      <td>4.86</td>\n",
                            "      <td>58</td>\n",
                            "      <td>7.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>100%</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>14</td>\n",
                            "      <td>29</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>1125</td>\n",
                            "      <td>within a few hours</td>\n",
                            "      <td>t</td>\n",
                            "      <td>f</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>5.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>2016-04-15</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>5.00</td>\n",
                            "      <td>60</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>t</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>14</td>\n",
                            "      <td>30</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>30</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>t</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>4.00</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1.0</td>\n",
                            "      <td>f</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>730</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>f</td>\n",
                            "      <td>2.0</td>\n",
                            "      <td>NaN</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows \u00d7 54 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   estimated_revenue_l365d last_review  \\\n",
                            "0                  13890.0  2024-10-19   \n",
                            "1                      0.0         NaN   \n",
                            "2                      0.0  2022-06-16   \n",
                            "3                      0.0  2016-04-15   \n",
                            "4                      NaN         NaN   \n",
                            "\n",
                            "   calculated_host_listings_count_shared_rooms  review_scores_communication  \\\n",
                            "0                                            0                         4.94   \n",
                            "1                                            0                          NaN   \n",
                            "2                                            0                         4.71   \n",
                            "3                                            0                         5.00   \n",
                            "4                                            0                          NaN   \n",
                            "\n",
                            "   review_scores_location  availability_60  host_listings_count  \\\n",
                            "0                    4.94               52                  8.0   \n",
                            "1                     NaN                0                  7.0   \n",
                            "2                    4.86               58                  7.0   \n",
                            "3                    5.00               60                  2.0   \n",
                            "4                     NaN                0                  1.0   \n",
                            "\n",
                            "  host_identity_verified host_response_rate  number_of_reviews_l30d  ...  \\\n",
                            "0                      t                80%                       0  ...   \n",
                            "1                      t                NaN                       0  ...   \n",
                            "2                      t               100%                       0  ...   \n",
                            "3                      t                NaN                       0  ...   \n",
                            "4                      f                NaN                       0  ...   \n",
                            "\n",
                            "  reviews_per_month maximum_minimum_nights availability_30  beds  \\\n",
                            "0              0.33                      2              25   4.0   \n",
                            "1               NaN                      4               0   5.0   \n",
                            "2              0.05                     14              29   2.0   \n",
                            "3              0.01                     14              30   1.0   \n",
                            "4               NaN                      3               0   NaN   \n",
                            "\n",
                            "  maximum_maximum_nights  host_response_time  has_availability  \\\n",
                            "0                   1125        within a day                 t   \n",
                            "1                    730                 NaN                 t   \n",
                            "2                   1125  within a few hours                 t   \n",
                            "3                     30                 NaN                 t   \n",
                            "4                    730                 NaN               NaN   \n",
                            "\n",
                            "   host_is_superhost  bedrooms  review_scores_value  \n",
                            "0                  f       3.0                 4.85  \n",
                            "1                  f       3.0                  NaN  \n",
                            "2                  f       1.0                 5.00  \n",
                            "3                NaN       1.0                 4.00  \n",
                            "4                  f       2.0                  NaN  \n",
                            "\n",
                            "[5 rows x 54 columns]"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Load datasets\n",
                "train_path = 'train_data.csv'\n",
                "test_path = 'test_f25.xlsx'\n",
                "\n",
                "df_train = pd.read_csv(train_path)\n",
                "df_test = pd.read_excel(test_path)\n",
                "\n",
                "print(f\"Train Shape: {df_train.shape}\")\n",
                "print(f\"Test Shape: {df_test.shape}\")\n",
                "df_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train Shape after dropping missing targets: (25386, 54)\n",
                        "Categorical Columns: 15\n",
                        "Numerical Columns: 38\n"
                    ]
                }
            ],
            "source": [
                "# Target Variable\n",
                "target_col = 'host_is_superhost'\n",
                "\n",
                "# Convert target to binary (t/f -> 1/0)\n",
                "df_train[target_col] = df_train[target_col].map({'t': 1, 'f': 0})\n",
                "\n",
                "# Check for missing values in target and drop them\n",
                "df_train = df_train.dropna(subset=[target_col])\n",
                "print(f\"Train Shape after dropping missing targets: {df_train.shape}\")\n",
                "\n",
                "# Separate Target and Features\n",
                "y = df_train[target_col]\n",
                "X = df_train.drop(columns=[target_col])\n",
                "\n",
                "# Drop columns that are entirely empty (all NaNs)\n",
                "X = X.dropna(axis=1, how='all')\n",
                "\n",
                "# --- Date Processing ---\n",
                "print(\"Processing Dates...\")\n",
                "date_cols = ['last_review', 'first_review']\n",
                "for col in date_cols:\n",
                "    if col in X.columns:\n",
                "        # Convert to datetime\n",
                "        X[col] = pd.to_datetime(X[col], errors='coerce')\n",
                "        if col in df_test.columns:\n",
                "            df_test[col] = pd.to_datetime(df_test[col], errors='coerce')\n",
                "        \n",
                "        # Create 'days_since' feature (relative to a reference date, e.g., today or max date)\n",
                "        ref_date = pd.Timestamp('2024-12-01') # Use a fixed recent date\n",
                "        X[f'days_since_{col}'] = (ref_date - X[col]).dt.days\n",
                "        df_test[f'days_since_{col}'] = (ref_date - df_test[col]).dt.days\n",
                "        \n",
                "        # Drop original date columns\n",
                "        X = X.drop(columns=[col])\n",
                "        df_test = df_test.drop(columns=[col])\n",
                "\n",
                "# --- Text Embedding (Amenities) ---\n",
                "print(\"Embedding Amenities (this may take a while)...\")\n",
                "if 'amenities' in X.columns:\n",
                "    # Load pre-trained model\n",
                "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "    \n",
                "    # Fill NaNs with empty string\n",
                "    X['amenities'] = X['amenities'].fillna('')\n",
                "    df_test['amenities'] = df_test['amenities'].fillna('')\n",
                "    \n",
                "    # Encode\n",
                "    train_embeddings = model.encode(X['amenities'].tolist(), show_progress_bar=True)\n",
                "    test_embeddings = model.encode(df_test['amenities'].tolist(), show_progress_bar=True)\n",
                "    \n",
                "    # Create DataFrame from embeddings\n",
                "    embedding_cols = [f'amenity_emb_{i}' for i in range(train_embeddings.shape[1])]\n",
                "    train_emb_df = pd.DataFrame(train_embeddings, columns=embedding_cols, index=X.index)\n",
                "    test_emb_df = pd.DataFrame(test_embeddings, columns=embedding_cols, index=df_test.index)\n",
                "    \n",
                "    # Concatenate and drop original column\n",
                "    X = pd.concat([X, train_emb_df], axis=1).drop(columns=['amenities'])\n",
                "    df_test = pd.concat([df_test, test_emb_df], axis=1).drop(columns=['amenities'])\n",
                "\n",
                "# Identify categorical and numerical columns (Refresh after new features)\n",
                "cat_cols = X.select_dtypes(include=['object']).columns\n",
                "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
                "\n",
                "print(f\"Categorical Columns: {len(cat_cols)}\")\n",
                "print(f\"Numerical Columns: {len(num_cols)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle Missing Values\n",
                "# For numerical, fill with median\n",
                "for col in num_cols:\n",
                "    median_val = X[col].median()  # Calculate median on Train\n",
                "    X[col] = X[col].fillna(median_val)\n",
                "    if col in df_test.columns:\n",
                "        df_test[col] = df_test[col].fillna(median_val)  # Apply Train median to Test\n",
                "\n",
                "# For categorical, fill with mode\n",
                "for col in cat_cols:\n",
                "    mode_val = X[col].mode()[0]  # Calculate mode on Train\n",
                "    X[col] = X[col].fillna(mode_val)\n",
                "    if col in df_test.columns:\n",
                "        df_test[col] = df_test[col].fillna(mode_val)  # Apply Train mode to Test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Encoded Train Features Shape: (25386, 34086)\n",
                        "Encoded Test Features Shape: (130, 34086)\n"
                    ]
                }
            ],
            "source": [
                "# One-Hot Encoding\n",
                "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
                "df_test_encoded = pd.get_dummies(df_test, columns=cat_cols, drop_first=True)\n",
                "\n",
                "# Align columns (Ensure train and test have same features)\n",
                "X_encoded, df_test_encoded = X_encoded.align(df_test_encoded, join='left', axis=1, fill_value=0)\n",
                "\n",
                "print(f\"Encoded Train Features Shape: {X_encoded.shape}\")\n",
                "print(f\"Encoded Test Features Shape: {df_test_encoded.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. Data Balancing\n",
                "\n",
                "We handle class imbalance using resampling.\n",
                "- **Option**: Set `SAMPLING_METHOD` to `'upsample'` or `'downsample'`.\n",
                "- **Upsampling (Default)**: Replicates minority class samples. **Pros**: Retains all information. **Cons**: Increases dataset size, potential for overfitting if not careful.\n",
                "- **Downsampling**: Removes majority class samples. **Pros**: Faster training. **Cons**: Loss of potentially valuable information."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Original Class Distribution:\n",
                        "host_is_superhost\n",
                        "0.0    17165\n",
                        "1.0     8221\n",
                        "Name: count, dtype: int64\n",
                        "\n",
                        "Performing Upsampling...\n",
                        "\n",
                        "Balanced Class Distribution:\n",
                        "host_is_superhost\n",
                        "0.0    17165\n",
                        "1.0    17165\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "SAMPLING_METHOD = 'upsample'  # Options: 'upsample', 'downsample'\n",
                "\n",
                "# Combine X and y for resampling\n",
                "train_data = pd.concat([X_encoded, y], axis=1)\n",
                "\n",
                "# Check class distribution\n",
                "print(\"Original Class Distribution:\")\n",
                "print(y.value_counts())\n",
                "\n",
                "# Separate majority and minority classes\n",
                "df_majority = train_data[train_data[target_col] == 0]\n",
                "df_minority = train_data[train_data[target_col] == 1]\n",
                "\n",
                "if SAMPLING_METHOD == 'upsample':\n",
                "    print(\"\\nPerforming Upsampling...\")\n",
                "    df_minority_upsampled = resample(df_minority, \n",
                "                                     replace=True,     # sample with replacement\n",
                "                                     n_samples=len(df_majority),    # to match majority class\n",
                "                                     random_state=42)\n",
                "    df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
                "    \n",
                "elif SAMPLING_METHOD == 'downsample':\n",
                "    print(\"\\nPerforming Downsampling...\")\n",
                "    df_majority_downsampled = resample(df_majority, \n",
                "                                       replace=False,    # sample without replacement\n",
                "                                       n_samples=len(df_minority),    # to match minority class\n",
                "                                       random_state=42)\n",
                "    df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
                "\n",
                "# Display new class counts\n",
                "print(\"\\nBalanced Class Distribution:\")\n",
                "print(df_balanced[target_col].value_counts())\n",
                "\n",
                "# Separate X and y again\n",
                "X_balanced = df_balanced.drop(columns=[target_col])\n",
                "y_balanced = df_balanced[target_col]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5. Feature Scaling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X_balanced)\n",
                "X_test_scaled = scaler.transform(df_test_encoded)\n",
                "\n",
                "X_scaled = pd.DataFrame(X_scaled, columns=X_balanced.columns)\n",
                "X_test_scaled = pd.DataFrame(X_test_scaled, columns=df_test_encoded.columns)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 6. Model Building & Hyperparameter Tuning\n",
                "\n",
                "### Hyperparameter Tuning Strategy\n",
                "We use `GridSearchCV` to find the optimal hyperparameters for each model. Here is the rationale for the chosen parameter ranges:\n",
                "\n",
                "- **MLP (Neural Network)**:\n",
                "    - `hidden_layer_sizes`: We test different architectures. `(50,)` is a simple model, `(100,)` adds width, and `(50, 50)` adds depth to capture more complex patterns.\n",
                "    - `activation`: `relu` is standard for deep learning, `tanh` can be better for some datasets.\n",
                "    - `alpha`: Regularization parameter to prevent overfitting. We test small values `0.0001` and `0.001`.\n",
                "\n",
                "- **Random Forest & Decision Tree**:\n",
                "    - `max_depth`: Controls tree complexity. `None` allows full growth (risk of overfitting), while `10`, `20` limit it.\n",
                "    - `min_samples_split`: Higher values (e.g., `10`) prevent the model from learning overly specific patterns (noise).\n",
                "    - `n_estimators` (RF only): Number of trees. More trees generally improve performance but increase computation.\n",
                "\n",
                "- **KNN**:\n",
                "    - `n_neighbors`: `3` captures local patterns (sensitive to noise), `7` is smoother.\n",
                "    - `weights`: `distance` gives more weight to closer neighbors, `uniform` treats all equally.\n",
                "\n",
                "- **Logistic Regression**:\n",
                "    - `C`: Inverse of regularization strength. Smaller values (e.g., `0.1`) specify stronger regularization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize results list and best_models dictionary\n",
                "# Run this cell once before running individual model cells\n",
                "results = []\n",
                "best_models = {}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing Logistic Regression ---\")\n",
                "lr_params = {\n",
                "    'C': [0.1, 1, 10]\n",
                "}\n",
                "clf = GridSearchCV(LogisticRegression(max_iter=100, random_state=42), lr_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['Logistic Regression'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'Logistic Regression',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing Decision Tree ---\")\n",
                "dt_params = {\n",
                "    'max_depth': [None, 10, 20, 30],\n",
                "    'min_samples_split': [2, 5, 10]\n",
                "}\n",
                "clf = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['Decision Tree'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'Decision Tree',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing Random Forest ---\")\n",
                "rf_params = {\n",
                "    'n_estimators': [50, 100, 200],\n",
                "    'max_depth': [None, 10, 20],\n",
                "    'min_samples_split': [2, 5]\n",
                "}\n",
                "clf = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['Random Forest'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'Random Forest',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing MLP (Neural Network) ---\")\n",
                "mlp_params = {\n",
                "    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
                "    'activation': ['relu', 'tanh'],\n",
                "    'alpha': [0.0001, 0.001]\n",
                "}\n",
                "clf = GridSearchCV(MLPClassifier(max_iter=100, random_state=42), mlp_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['MLP (Neural Network)'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'MLP (Neural Network)',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing KNN ---\")\n",
                "knn_params = {\n",
                "    'n_neighbors': [3, 5, 7],\n",
                "    'weights': ['uniform', 'distance']\n",
                "}\n",
                "clf = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['KNN'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'KNN',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Processing Naive Bayes ---\")\n",
                "nb_params = {}\n",
                "clf = GridSearchCV(GaussianNB(), nb_params, cv=5, scoring='accuracy', n_jobs=1, verbose=3)\n",
                "clf.fit(X_scaled, y_balanced)\n",
                "    # Calculate additional metrics\n",
                "    y_pred = clf.best_estimator_.predict(X_scaled)\n",
                "    rec = recall_score(y_balanced, y_pred)\n",
                "    f1 = f1_score(y_balanced, y_pred)\n",
                "\n",
                "\n",
                "best_models['Naive Bayes'] = clf.best_estimator_\n",
                "results.append({\n",
                "    'Model': 'Naive Bayes',\n",
                "    'Best Score': clf.best_score_,\n",
                "    'Best Params': clf.best_params_,\n",
                "        'Recall': rec,\n",
                "        'F1 Score': f1\n",
                "})\n",
                "print(f\"  Best Score: {clf.best_score_:.4f}\")\n",
                "print(f\"  Best Params: {clf.best_params_}\")\n",
                "    print(f\"  Recall: {rec:.4f}\")\n",
                "    print(f\"  F1 Score: {f1:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display results dataframe\n",
                "results_df = pd.DataFrame(results).sort_values(by='Best Score', ascending=False)\n",
                "print(\"\\n--- Model Selection Report ---\")\n",
                "print(results_df)\n",
                "\n",
                "# Select the best performing model overall\n",
                "if not results_df.empty:\n",
                "    best_model_name = results_df.iloc[0]['Model']\n",
                "    best_model_score = results_df.iloc[0]['Best Score']\n",
                "    final_model = best_models[best_model_name]\n",
                "\n",
                "    print(f\"\\nSelected Best Model: {best_model_name}\")\n",
                "    print(f\"Reason: It achieved the highest cross-validation accuracy of {best_model_score:.4f} among all tested models.\")\n",
                "    \n",
                "    # Compare with Rule-Based\n",
                "    print(\"\\n--- Comparison with Rule-Based Logic ---\")\n",
                "    final_preds = final_model.predict(X_test_scaled)\n",
                "    agreement = (final_preds == rule_based_preds).mean()\n",
                "    print(f\"Agreement between Best Model and Rule-Based Logic: {agreement:.2%}\")\n",
                "else:\n",
                "    print(\"No results found. Please run the model cells above.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Rule-Based Validation ---\n",
                "print(\"\\n--- Rule-Based Validation ---\")\n",
                "\n",
                "def check_superhost_criteria(row):\n",
                "    # Criteria based on Airbnb Superhost requirements\n",
                "    # 1. 10+ stays (or 3 stays + 100 nights) -> approximated by number_of_reviews_ltm >= 10\n",
                "    # 2. Response rate >= 90%\n",
                "    # 3. Rating >= 4.8\n",
                "    # 4. Cancellation rate < 1% (Not available in dataset, assumed met)\n",
                "    \n",
                "    # Rating Check\n",
                "    rating_ok = False\n",
                "    if pd.notna(row.get('review_scores_rating')):\n",
                "        rating_ok = row['review_scores_rating'] >= 4.8\n",
                "    elif pd.notna(row.get('review_scores_value')):\n",
                "        rating_ok = row['review_scores_value'] >= 4.8\n",
                "        \n",
                "    # Response Rate Check\n",
                "    response_ok = False\n",
                "    if pd.notna(row.get('host_response_rate')):\n",
                "        # Convert '100%' string to 100 number\n",
                "        try:\n",
                "            rate = float(str(row['host_response_rate']).replace('%', ''))\n",
                "            response_ok = rate >= 90\n",
                "        except:\n",
                "            pass\n",
                "    else:\n",
                "        # If missing, assume ok if other criteria met (lenient)\n",
                "        response_ok = True\n",
                "            \n",
                "    # Stays Check\n",
                "    stays_ok = False\n",
                "    if pd.notna(row.get('number_of_reviews_ltm')):\n",
                "        stays_ok = row['number_of_reviews_ltm'] >= 10\n",
                "    elif pd.notna(row.get('number_of_reviews')):\n",
                "        stays_ok = row['number_of_reviews'] >= 10\n",
                "        \n",
                "    return 1 if (rating_ok and response_ok and stays_ok) else 0\n",
                "\n",
                "# Apply to Test Data (Need original columns, so we reload or use df_test before dropping)\n",
                "# Since we dropped columns in preprocessing, we'll reload a fresh copy for this validation\n",
                "df_test_raw = pd.read_excel('test_f25.xlsx')\n",
                "rule_based_preds = df_test_raw.apply(check_superhost_criteria, axis=1)\n",
                "\n",
                "print(f\"Rule-Based Predictions (First 10): {rule_based_preds.head(10).tolist()}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 7. Final Prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predict on Test Data\n",
                "final_predictions = final_model.predict(X_test_scaled)\n",
                "\n",
                "# Create submission dataframe\n",
                "submission = pd.DataFrame({\n",
                "    'No': df_test['No'],\n",
                "    'host_is_superhost_pred': final_predictions\n",
                "})\n",
                "\n",
                "# Map 1/0 back to t/f\n",
                "submission['host_is_superhost_pred'] = submission['host_is_superhost_pred'].map({1: 't', 0: 'f'})\n",
                "\n",
                "submission.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save to Excel\n",
                "submission.to_excel('prediction_result.xlsx', index=False)\n",
                "print(\"Prediction saved to prediction_result.xlsx\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 8. Summary\n",
                "\n",
                "**Model Building Process:**\n",
                "1.  **Data Preprocessing**: \n",
                "    -   Target variable `host_is_superhost` was converted to binary.\n",
                "    -   Missing values were filled (median for numerical, mode for categorical).\n",
                "    -   Categorical variables were One-Hot Encoded.\n",
                "    -   Train and Test features were aligned to ensure consistency.\n",
                "    -   Data was balanced using upsampling to address class imbalance.\n",
                "    -   Features were scaled using StandardScaler.\n",
                "\n",
                "2.  **Model Evaluation & Tuning**:\n",
                "    -   We performed GridSearchCV for multiple models: Logistic Regression, Decision Tree, Random Forest, MLP, KNN, and Naive Bayes.\n",
                "    -   Hyperparameters such as hidden layers for MLP, tree depth for Decision Tree/Random Forest, and neighbors for KNN were tuned.\n",
                "    -   5-fold cross-validation was used to ensure robust evaluation.\n",
                "\n",
                "3.  **Prediction**:\n",
                "    -   The model with the highest cross-validation accuracy was selected.\n",
                "    -   Predictions were generated for the test dataset and saved to `prediction_result.xlsx`."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}